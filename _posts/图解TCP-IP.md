---
title: 图解TCP/IP
date: 2020-11-07 17:08:52
tags: 计算机网络
---

# 分层参考模型

ISO制定的OSI参考模型，分成了七层。

![da](D:\devApp\myblog\source\_posts\图解TCP-IP\image-20201031142356957.png)

在这一模型中，每个分层都接收由它下一层所提供的特定服务，并且负责为自己的上一层提供特定的服务。上下层之间进行交互时所遵循的约定叫做“接口”。同一层之间的交互所遵循的约定叫做“协议。

## 各层的功能

![asda](D:\devApp\myblog\source\_posts\图解TCP-IP\image-20201031144647886.png)

## 网络层和数据链路层的区别

网络层与数据链路层都是基于目标地址将数据发送给接收端的，但是网络层负责将整个数据发送给最终目标地址，而数据链路层则只负责发送一个分段内的数据。

# 传输方式的分类

## 1、面向有连接型和面向无连接型

面向无连接型包括以太网、UDP等协议。

面向有连接型包括ATM、帧中继、TCP等协议。

## 2、电路交换和分组交换

在分组交换中，由**分组交换机(路由器)**连接通信线路。分组交换的大致处理过程是:发送端计算机将数据分组发送给路由器，路由器收到这些分组数据以后，**缓存到自己的缓冲区**，然后再转发给目标计算机。因此，分组交换也有另一个名称:蓄积交换。路由器接收到数据以后会按照顺序缓存到相应的队列当中，再以**先进先出的顺序将它们逐一发送出去**。

## 3、根据接收端数量分类

单播 广播 多播 任播

# 地址

MAC地址和IP地址在标识一个通讯主体时虽然都具有唯一性，但是只有IP地址具有层次性。

# 网络的构成要素

![image-20201103150203879](D:\devApp\myblog\source\_posts\图解TCP-IP\image-20201103150203879.png)

![image-20201103150226220](D:\devApp\myblog\source\_posts\图解TCP-IP\image-20201103150226220.png)

## 传输速率和吞吐量

​		在数据传输的过程中，两个**设备之间**数据流动的物理速度称为**传输速率**。单位为bps (Bits Per Second,每秒比特数)。从严格意义上讲，**各种传输媒介中信号的流动速度是恒定的。因此，即使数据链路的传输速率不相同，也不会出现传输的速度忽快忽慢的情况**"。传输速率高也不是指单位数据流动的速度有多快，而是指单位时间内传输的数据量有多少。以我们生活中的道路交通为例，低速数据链路就如同车道较少无法让很多车同时通过的情况。与之相反，高速数据链路就相当于有多个车道，一次允许更多车辆行驶的道路。传输速率又称作带宽( Bandwidth)。带宽越大网络传输能力就越强。

​		此外，**主机之间**实际的传输速率被称作**吞吐量**。其单位与带宽相同,都是bps (Bits Per Second)。**吞吐量这个词不仅街量带宽，同时也衡量主机的CPU处理能力、网络的拥堵程度、报文中数据字段的占有份额(不含报文首部，只计算数据字段本身)等信息**。

## 传输设备

1、中继器：物理层

①物理层面上延长网络的设备，但不能无限延长。负责对减弱的信号进行**放大和发送**。

②只负责将电信号转换为光信号，因此**不能在传输速率不同的媒介中转发**。也**不负责判断数据是否发生错误**。

③集线器可以看成多口中继器，每个端口都可以成为一个中继器。



2、网桥（2层交换机）：数据链路层

●网桥根据数据帧的内容转发数据给相邻的其他网络
●网桥**没有连接网段个数的限制**
●网桥基本只用于连接相同类型的网络。但是有时也可以连接**传输速率不同**的网络。

①数据链路的数据帧有一数据位叫做FCS，用以校验数据是否正确送达目的地。网桥通过检查这个域的值来**丢弃损坏的数据**。

②网桥还能通过地址自学机制和过滤功能**控制网络流量**。

③以太网等网络中经常使用的交换集线器(Hub")，现在基本也属于网桥的一种。交换集线器中连接电缆的每个端口都能提供类似网桥的功能。

④自学式网桥。

![image-20201103164819940](D:\devApp\myblog\source\_posts\图解TCP-IP\image-20201103164819940.png)

3、路由器（3层交换机）：网络层

网桥是根据MAC地址进行处理，而路由器是根据IP地址进行处理

4、网关

网关是OSI参考模型中负责将从传输层到应用层的数据进行转换和转发的设备。它与4~7层交换机一样都是处理传输层及以上的数据，但是**网关不仅转发数据还负责对数据进行转换**，它通常会使用一个表示层或应用层网关，**在两个不能进行直接通信的协议之间进行翻译，最终实现两者之间的通信**。

# 数据链路层

## MAC地址

MAC地址长48比特

![image-20201106102737993](D:\devApp\myblog\source\_posts\图解TCP-IP\image-20201106102737993.png)

## 共享介质型网络

在这种方式下，设备之间使用同一个载波信道进行发送和接收，为此基本上采用半双工通信方式，并对介质进行访问控制。

共享介质型网络有两种介质访问控制方式：①争用方式②令牌传递方式



### 争用方式（CSMA载波监听多路访问）



![dasd](D:\devApp\myblog\source\_posts\图解TCP-IP\image-20201106103313606.png)

CSMA/CD是一种CSMA改良的方式，其工作原理如下

* 如果载波信道上没有数据流动，则任何站都可以发送数据。
* 检查是否会发生冲突。一旦发生冲突时，放弃发送数据，同时立即释放载波信道。
* 放弃发送以后，随机延时一段时间，再重新争用介质，重新发送帧。

### 令牌传递方式

![dawdw](D:\devApp\myblog\source\_posts\图解TCP-IP\image-20201106104106797.png)

优点：①不会有冲突②每个站都有通过平等循环获得令牌的机会，因此即使网络拥堵也不会导致性能下降。

缺点：数据链路的利用率达不到100%。

## 非共享介质网络

每个站直连交换机，由交换机负责转发数据帧，全双工通信。

缺点：一旦交换机发生故障，与之相连的所有计算机将无法通信。

# 网络层

## IP

网络层的主要作用是“实现终端节点之间的通信”。这种终端节点之间的通信也叫“点对点( end-to-end)通信”。(节点是主机和路由器的统称)

IP是跨越网络传送数据包,使整个互联网都能收到数据的协议,使用IP地址作为主机的标识.

虽然IP也是分组交换的一种协议,但是**它不具有重发机制,即使分组数据包未能到达对端主机也不会重发.因此属于非可靠性传输协议**.

### 网络层和数据链路层区别

仔细分析一下机票和火车票，不难发现，每张票只能够在某一限定区间内移动。此处的“区间内”就如同通信网络上的数据链路。而这个区间内的出发地点.和目的地点就如同某一个数据链路的源地址和目标地址等首部信息"。整个全程的行程表的作用就相当于网络层。

### IP基础知识

IP大致分为三大作用模块，它们是**IP寻址**、**路由**（最终节点为止的转发)以及**IP分包与组包**。

#### IP地址

MAC地址是用来识别同一链路中不同计算机的一种识别码

IP地址用于在连接到网络中的所有主机中识别出进行通信的目标地址

#### IP为什么采用面向无连接

主要有两点原因:一是为了简化，二是为了提速。面向连接比起面向无连接处理相对复杂。甚至管理每个连接本身就是一个相当繁琐的事情。此外，每次通信之前都要事先建立连接，又会降低处理速度。需要有连接时，可以委托上一层提供此项服务。因此，IP为了实现简单化与高速化采用面向无连接的方式。

#### 路由控制

<img src="D:\devApp\myblog\source\_posts\图解TCP-IP\image-20211227154848944.png" alt="image-20211227154848944" style="zoom:67%;" />

数据链路实现某一区间内的通信,及两个直接相连的主机或路由器间的通信.而IP实现直接至最终目标地址的通信.

### IP地址基础知识

IP地址由**网络标识**和**主机标识**两部分组成

#### 多播和广播

<img src="D:\devApp\myblog\source\_posts\图解TCP-IP\image-20211230095457645.png" alt="image-20211230095457645" style="zoom: 67%;" />

路由器不转发广播的包,但是可以复制多播的包.

### 路由控制

下图是发送IP包的实例

<img src="D:\devApp\myblog\source\_posts\图解TCP-IP\image-20211230103655364.png" alt="image-20211230103655364" style="zoom:67%;" />

### 报文的分片与重组

任何一台主机都有必要对IP分片（ IP Fragmentation)进行相应的处理。分片往往在网络上遇到比较大的报文无法一下子发送出去时才会进行处理。

由于以太网的默认MTU是1500字节，因此4342字节的IP数据报无法在一个帧当中发送完成。这时，路由器将此IP数据报划分成了3个分片进行发送。而这种分片处理只要路由器认为有必要，会周而复始地进行”。

**经过分片之后的P数据报在被重组的时候，只能由目标主机进行。路由器虽然做分片但不会进行重组。**

### 路径MTU发现

所谓路径MTU (Path MTU)是指从发送端主机到接收端主机之间不需要分片时最大MTU的大小。**即路径中存在的所有数据链路中最小的MTU**。而路径MTU发现从发送主机按照路径MTU的大小将数据报分片后进行发送。进行路径MTU发现，就可以避免在中途的路由器上进行分片处理.

### IPv6

#### IPv6的特点

- IPv4的地址长度为4个8位字节,即32比特.而IPv6的地址长度则是128比特,一般携程8个16位字节.

<img src="D:\devApp\myblog\source\_posts\图解TCP-IP\image-20211230132817732.png" alt="image-20211230132817732" style="zoom:67%;" />



**IPv6的分片处理旨在作为起点的发送端主机上运行,路由器不参与分片.因此IPv6中"路径MTU发现"功能必不可少**

## IP相关协议

### DNS

#### DNS查询

<img src="D:\devApp\myblog\source\_posts\图解TCP-IP\image-20211230165719225.png" alt="image-20211230165719225" style="zoom:67%;" />

### ARP

从分组数据包的IP地址中解析出物理地址(MAC地址)的一种协议

ARP是一种解决地址问题的协议。以目标IP地址为线索，用来定位下一个应该接收数据分包的网络设备对应的MAC地址。如果目标主机不在同一个链路上时，可以通过ARP查找下一跳路由器的MAC地址。不过ARP只适用于IPv4.

过程:主机A为了获得主机B的MAC地址，起初要通过广播发送一个ARP请求包。这个包中包含了想要了解其MAC地址的主机I地址。也就是说，ARP请求包中已经包含了主机B的IP地址172.20.1.2。由于广播的包可以被同一个链路上所有的主机或路由器接收，因此ARP的请求包也就会被这同一个链路上所有的主机和路由器进行解析。如果ARP请求包中的目标I地址与自己的IP地址一致，那么这个节点就将自己的MAC地址塞人ARP响应包返回给主机A。

#### IP和MAC地址缺一不可

如图所示，主机A想要发送IP数据报给主机B时必须得经过路由器C。即使知道了主机B的MAC地址，由于路由器C会隔断两个网络，还是无法实现直接从主机A发送数据报给主机B。此时，主机A必须得先将数据报发送给路由器C的MAC地址C1。

<img src="D:\devApp\myblog\source\_posts\图解TCP-IP\image-20211231140405938.png" alt="image-20211231140405938" style="zoom:80%;" />

此外，假定MAC地址就用广播地址，那么路由器D也将会收到该广播消息。于是路由器D又将该消息转发给路由器C，导致数据包被重复发送两次。
在以太网上发送IP包时，“下次要经由哪个路由器发送数据报”这一信息非常重要。而这里的“下一个路由器”就是相应的 MAC地址。

### ICMP

ICMP的主要功能包括，确认IP包是否成功送达目标地址，通知在发送过程当中IP包被废弃的具体原因，改善网络设置等。有了这些功能以后，就可以获得网络是否正常、设置是否有误以及设备有何异常等信息，从而便于进行网络上的问题诊断。

### DHCP

有了DHCP，实现自动设置IP地址、统一管理IP地址分配，计算机只要连接到网络,就可以进行TCP/IP通信。也就是说，DHCP让即插即用"变得可能。而 DHCP不仅在IPv4中，在IPv6中也可以使用。

### IP隧道

在一个如图所示的网络环境里，网络A、B使用IPv6，如果处于中间位置的网络C支持使用IPv4的话，网络A与网络B之间将无法直接进行通信。为了让它们之间正常通信，这时必须得采用IP隧道的功能。

<img src="D:\devApp\myblog\source\_posts\图解TCP-IP\image-20220104093929815.png" alt="image-20220104093929815" style="zoom:50%;" />

IP隧道中可以将那些从网络A发过来的IPv6的包统和为一个数据，再为之追加一个IPv4的首部以后转发给网络C。

一般情况下，紧接着IP首部的是TCP 或UDP的首部。然而，现在的应用当中“IP首部的后面还是IP首部”或者“IP首部的后面是IPv6的首部”等情况与日俱增。这种在网络层的首部后面继续追加网络层首部的通信方法就叫做“IP隧道”。

# 传输层



## TCP和UDP区分

<img src="D:\devApp\myblog\source\_posts\图解TCP-IP\image-20211221102623825.png" alt="image-20211221102623825" style="zoom: 33%;" />

## 端口号

<img src="D:\devApp\myblog\source\_posts\图解TCP-IP\image-20211221102757217.png" alt="image-20211221102757217" style="zoom:33%;" />

TCP/IP或UDP/IP通信中通常采用5个信息来识别一个通信。它们是**“源IP地址”、“目标IP地址”、“协议号”、“源端口号”、“目标端口号”**。只要其中某一项不同，则被认为是其他通信。

## TCP

tcp首部最少20个字节，TCP首部有20个字节的固定数据，用来存放报文传输过程所需的信息。

`UDP`报头包括4个字段，每个字段占用2个字节

TCP通过**检验和**、**序列号**、**确认应答**、**重发控制**、**连接管理**以及**窗口控制**等机制实现可靠性传输。

### 通过序列号和确认应答提高可靠性

上述这些确认应答处理、重发控制以及重复控制等功能都可以通过序列号实现。序列号是按顺序给发送数据的每一个字节(8位字节）都标上号码的编号。接收端查询接收数据TCP首部中的序列号和数据的长度，将自己下一步应该接收的序号作为确认应答返送回去。就这样，通过序列号和确认应答号，TCP可以实现可靠传输。

<img src="D:\devApp\myblog\source\_posts\图解TCP-IP\image-20211223102350624.png" alt="image-20211223102350624" style="zoom: 67%;" />

### 重发超时如何确定

重发超时是指在重发数据之前，等待确认应答到来的那个特定时间间隔。如果超过了这个时间仍未收到确认应答，发送端将进行数据重发。

情况发生何种变化，都必须保持这一特性。为此，它在每次发包时都会计算往返时间及其偏差'。将这个往返时间和偏差相加重发超时的时间，就是比这个总和稍大一点的时间,如下图

<img src="D:\devApp\myblog\source\_posts\图解TCP-IP\image-20211223104036166.png" alt="image-20211223104036166" style="zoom:67%;" />

在BSD的Unix 以及Windows系统中，超时都以0.5秒为单位进行控制，因此重发超时都是0.5秒的整数倍'。不过，由于最初的数据包还不知道往返时间，所以其重发超时一般设置为6秒左右。

数据被重发之后若还是收不到确认应答，则进行再次发送。此时，等待确认应答的时间将会以2倍、4倍的指数函数延长。

此外，数据也不会被无限、反复地重发。达到一定重发次数之后，如果仍没有任何确认应答返回，就会判断为网络或对端主机发生了异常，强制关闭连接。并且通知应用通信异常强行终止。

### 连接管理

<img src="D:\devApp\myblog\source\_posts\图解TCP-IP\image-20211223104643218.png" alt="image-20211223104643218" style="zoom:67%;" />

### 利用窗口控制提高速度

**窗口大小就是指无需等待确认应答而可以继续发送数据的最大值**。下图中,窗口大小为4个段

<img src="D:\devApp\myblog\source\_posts\图解TCP-IP\image-20211223112941083.png" alt="image-20211223112941083" style="zoom: 67%;" />

如图所示，发送数据中高亮圈起的部分正是前面所提到的窗口。在这个窗口内的数据即便没有收到确认应答也可以发送出去。此外，从该窗口中能看到的数据因其某种数据已在传输中丢失，所以发送端才能收到确认应答，这种情况也需进行重发。为此，**发送端主机在等到确认应答返回之前，必须在缓冲区中保留这部分数据**。

**在滑动窗口以外的部分包括尚未发送的数据以及已经确认对端已收到的数据**。当数据发出后若如期收到确认应答就可以不用再进行重发，此时数据就可以从缓存区清除。

收到确认应答的情况下，将窗口滑动到确认应答中的序列号的位置。这样可以顺序地将多个段同时发送提高通信性能。这种机制也被称为滑动窗口控制。



<img src="D:\devApp\myblog\source\_posts\图解TCP-IP\image-20211223135446077.png" alt="image-20211223135446077" style="zoom:67%;" />

### 窗口控制与重发控制

- 确认应答未能及时返回

首先，我们先考虑确认应答未能返回的情况。在这种情况下，数据已经到达对端，是不需要再进行重发的。然而，在没有使用窗口控制的时候，没有收到确认应答的数据都会被重发。而使用了窗口控制，就如图所示，某些确认应答即便丢失也无需重发。

<img src="D:\devApp\myblog\source\_posts\图解TCP-IP\image-20211223140236249.png" alt="image-20211223140236249" style="zoom:67%;" />

如上图所示,即使接收端已经接收到了1-1000的数据,并且发送了确认应答1001,但是确认应答在传输的过程中由于种种原因未能到达发送端.这时会继续发送1001-2000数据,接收端收到后会发送确认应答2001,这个如果能成功发送的话则发送端就知道2001前面的数据均成功发送.

- 报文丢失的情况

如图所示。当某一报文段丢失后，发送端会一直收到序号为1001的确认应答，这个确认应答好像在提醒发送端“我想接收的是从1001开始的数据”。因此，在窗口比较大，又出现报文段丢失的情况下，同一个序号的确认应答将会被重复不断地返回。而**发送端主机如果连续3次收到同一个确认应答**，就会将其所对应的数据进行重发。这种机制比之前提到的超时管理更加高效，因此也被称作高速重发控制。(之所以连续收到3次而不是两次的理由是内为、即使数据段的序号被替换两次也不会触发重发机制。)

<img src="D:\devApp\myblog\source\_posts\图解TCP-IP\image-20211223140933294.png" alt="image-20211223140933294" style="zoom:50%;" />

### 流量控制

发送端根据自己的实际情况发送数据。但是，接收端可能收到的是一个毫无关系的数据包又可能会在处理其他问题上花费一些时间。因此在为这个数据包做其他处理时会耗费一些时间，甚至在高负荷的情况下无法接收任何数据。如此一来，如果接收端将本应该接收的数据丢弃的话，就又会触发重发机制，从而导致网络流量的无端浪费。

为了防止这种现象的发生，TCP提供一种机制可以让发送端根据接收端的实际接收能力控制发送的数据量。这就是所谓的流控制。它的具体操作是，接收端主机向发送端主机通知自己可以接收数据的大小，于是发送端会发送不超过这个限度的数据。该大小限度就被称作窗口大小。在前面所介绍的**窗口大小的值就是由接收端主机决定的**。.**TCP首部中，专门有一个字段用来通知窗口大小**。接收主机将自己可以接收的缓冲区大小放入这个字段中通知给发送端。

<img src="D:\devApp\myblog\source\_posts\图解TCP-IP\image-20211223143220983.png" alt="image-20211223143220983" style="zoom:67%;" />

如图所示，当接收端收到从3001号开始的数据段后其缓冲区即满，不得不暂时停止接收数据。之后，在收到发送窗口更新通知后通信才得以继续进行。如果这个窗口的更新通知在传送途中丢失，可能会导致无法继续通信。为避免此类问题的发生，发送端主机会时不时的发送一个叫做窗口探测的数据段，此数据段仅含一个字节以获取最新的窗口大小信息。

### 拥塞控制

对于拥塞控制来说，TCP 每条连接都需要维护两个核心状态: - 拥塞窗口（Congestion Window，cwnd） - 慢启动阈值（Slow Start Threshold，ssthresh）

涉及到的算法有这几个: - 慢启动 - 拥塞避免 - 快速重传和快速恢复

#### 拥塞窗口

拥塞窗口（Congestion Window，cwnd）是指目前自己还能传输的数据量大小。

那么之前介绍了接收窗口的概念，两者有什么区别呢？ - 接收窗口(rwnd)是接收端给的限制 - 拥塞窗口(cwnd)是发送端的限制

```text
发送窗口大小 = min(rwnd, cwnd)
```

取两者的较小值。而拥塞控制，就是来控制cwnd即拥塞窗口的变化。

#### 慢启动

刚开始进入传输数据的时候，你是不知道现在的网路到底是稳定还是拥堵的，如果做的太激进，发包太急，那么疯狂丢包，造成雪崩式的网络灾难。

因此，拥塞控制首先就是要采用一种保守的算法来慢慢地适应整个网路，这种算法叫慢启动。运作过程如下:

- 首先，三次握手，双方宣告自己的接收窗口大小
- 双方初始化自己的**拥塞窗口**(cwnd)大小
- 在开始传输的一段时间，发送端每收到一个 ACK，拥塞窗口大小加 1，也就是说，每经过一个 RTT，cwnd 翻倍。如果说初始窗口为 10，那么第一轮 10 个报文传完且发送端收到 ACK 后，cwnd 变为 20，第二轮变为 40，第三轮变为 80，依次类推。

难道就这么无止境地翻倍下去？当然不可能。它的阈值叫做**慢启动阈值**，当 cwnd 到达这个阈值就不会涨的那么快乐,接下来就到了拥塞避免要发挥作用了

#### 拥塞避免

原来每收到一个 ACK，cwnd 加1，现在到达阈值了，cwnd 只能加这么一点: **1 / cwnd**。那你仔细算算，一轮 RTT 下来，收到 cwnd 个 ACK, 那最后拥塞窗口的大小 cwnd 总共才增加 1。

也就是说，以前一个 RTT 下来，cwnd翻倍，现在cwnd只是增加 1 而已。

当然，**慢启动**和**拥塞避免**是一起作用的，是一体的。

#### 快速重传和快速恢复

#### 快速重传

在 TCP 传输的过程中，如果发生了丢包，即接收端发现数据段不是按序到达的时候，接收端的处理是重复发送之前的 ACK。

比如第 5 个包丢了，即使第 6、7 个包到达的接收端，接收端也一律返回第 4 个包的 ACK。当发送端收到 3 个重复的 ACK 时，意识到丢包了，于是马上进行重传，不用等到一个 RTO 的时间到了才重传。

这就是**快速重传**，它解决的是**是否需要重传**的问题。

#### 选择性重传

那你可能会问了，既然要重传，那么只重传第 5 个包还是第5、6、7 个包都重传呢？

当然第 6、7 个都已经到达了，TCP 的设计者也不傻，已经传过去干嘛还要传？干脆记录一下哪些包到了，哪些没到，针对性地重传。

在收到发送端的报文后，接收端回复一个 ACK 报文，那么在这个报文首部的可选项中，就可以加上SACK这个属性，通过left edge和right edge告知发送端已经收到了哪些区间的数据报。因此，即使第 5 个包丢包了，当收到第 6、7 个包之后，接收端依然会告诉发送端，这两个包到了。剩下第 5 个包没到，就重传这个包。这个过程也叫做**选择性重传(SACK，Selective Acknowledgment)**，它解决的是**如何重传**的问题。

#### 快速恢复

当然，发送端收到三次重复 ACK 之后，发现丢包，觉得现在的网络已经有些拥塞了，自己会进入**快速恢复**阶段。

在这个阶段，发送端如下改变： - 拥塞阈值降低为 cwnd 的一半 - cwnd 的大小变为拥塞阈值 - cwnd 线性增加

### 提高网络利用率的规范

- Nagle算法

该算法是指发送端即使还有应该发送的数据，但如果这部分数据很少的话，则进行延迟发送的一种处理机制。具体来说，就是仅在下列任意一种条件下才能发送数据。如果两个条件都不满足，那么暂时等待一段时间以后再进行数据发送。

①已发送的数据都已经收到确认应答时	②可以发送最大段长度(MSS)的数据时

- 延迟确认应答

每个段的接收者收到完好的段时都会向发送者回送小的确认分组,如果发送者没有在指定的窗口时间内收到确认信息,发送者就认为分组已经被破坏并重发数据.

由于确认报文很小,所以tcp允许在发往相同方向的输出数据分组中对其进行"捎带".为了增加确认报文找到同向传输数据分组的可能性,很多tcp栈都实现了一种"延迟确认"算法,延迟确认算法会在一个特定的窗口时间内将输出的确认存放在缓冲区中,以寻找能够捎带它的输出数据分组,如果在那个时段内没有输出数据分组,就将确认信息放在单独的分组中传送.

- 捎带应答

## TFO

TCP 快速打开(TCP Fast Open)流程如下

### 首次三次握手

- 首先客户端发送SYN给服务端，服务端接收到。

- 现在服务端不是立刻回复 SYN + ACK，而是通过计算得到一个SYN Cookie, 将这个Cookie放到 TCP 报文的 Fast Open选项中，然后才给客户端返回。

- 客户端拿到这个 Cookie 的值缓存下来。后面正常完成三次握手。

### 后面的三次握手

在后面的三次握手中，客户端会将之前缓存的 Cookie.以及SYN 和HTTP请求(是的，你没看错)发送给服务端，服务端验证了 Cookie 的合法性，如果不合法直接丢弃；如果是合法的，那么就正常返回SYN + ACK。

重点来了，现在服务端能向客户端发 HTTP 响应了！这是最显著的改变，三次握手还没建立，仅仅验证了 Cookie 的合法性，就可以返回 HTTP 响应了。

当然，客户端的ACK还得正常传过来，不然怎么叫三次握手嘛。

流程如下

<img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220609140950701.png" alt="image-20220609140950701" style="zoom:50%;" />

### TFO的优势

TFO 的优势并不在与首轮三次握手，而在于后面的握手，在拿到客户端的 Cookie 并验证通过以后，可以直接返回 HTTP 响应，充分利用了**1 个RTT**(Round-Trip Time，往返时延)的时间**提前进行数据传输**，积累起来还是一个比较大的优势。



## 半连接队列和 SYN Flood 

三次握手前，服务端的状态从CLOSED变为LISTEN, 同时在内部创建了两个队列：**半连接队列**和**全连接队列**，即**SYN队列**和**ACCEPT队列**。

### 半连接队列

当客户端发送SYN到服务端，服务端收到以后回复ACK和SYN，状态由LISTEN变为SYN_RCVD，此时这个连接就被推入了**SYN队列**，也就是**半连接队列**。

### 全连接队列

当客户端返回ACK, 服务端接收后，三次握手完成。这个时候连接等待被具体的应用取走，在被取走之前，它会被推入另外一个 TCP 维护的队列，也就是**全连接队列(Accept Queue)**。

### SYN Flood 攻击原理

SYN Flood 属于典型的 DoS/DDoS 攻击。其攻击的原理很简单，就是用客户端在短时间内伪造大量不存在的 IP 地址，并向服务端疯狂发送SYN。对于服务端而言，会产生两个危险的后果:

1. 处理大量的SYN包并返回对应ACK, 势必有大量连接处于SYN_RCVD状态，从而占满整个**半连接队列**，无法处理正常的请求。
2. 由于是不存在的 IP，服务端长时间收不到客户端的ACK，会导致服务端不断重发数据，直到耗尽服务端的资源。

### 如何应对 SYN Flood 攻击？

1. 增加 SYN 连接，也就是增加半连接队列的容量。
2. 减少 SYN + ACK 重试次数，避免大量的超时重发。
3. 利用 SYN Cookie 技术，在服务端接收到SYN后不立即分配连接资源，而是根据这个SYN计算出一个Cookie，连同第二次握手回复给客户端，在客户端回复ACK的时候带上这个Cookie值，服务端验证 Cookie 合法之后才分配连接资源。

# 路由协议

自治系统（路由选择域)内部动态路由采用的协议是域内路由协议，即 IGP。而自治系统之间的路由控制采用的是域间路由协议，即 EGP。

### 路由算法

路由控制有各种各样的算法，其中最具代表性的有两种，是**距离向量**(Distance-Vector)算法和**链路状态**(Link-State)算法。

<img src="D:\devApp\myblog\source\_posts\图解TCP-IP\image-20220104131150918.png" alt="image-20220104131150918" style="zoom:50%;" />
